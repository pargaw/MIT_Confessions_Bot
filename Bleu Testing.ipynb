{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-479964dbf7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBLEU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-479964dbf7c1>\u001b[0m in \u001b[0;36mfetch_data\u001b[0;34m(cand, ref)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mreference_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcandidate_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peniel/anaconda/lib/python2.7/codecs.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "import json\n",
    "\n",
    "\n",
    "def fetch_data(cand, ref):\n",
    "    \"\"\" Store each reference and candidate sentences as a list \"\"\"\n",
    "    references = []\n",
    "    if '.txt' in ref:\n",
    "        reference_file = codecs.open(ref, 'r', 'utf-8')\n",
    "        references.append(reference_file.readlines())\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(ref):\n",
    "            for f in files:\n",
    "                reference_file = codecs.open(os.path.join(root, f), 'r', 'utf-8')\n",
    "                references.append(reference_file.readlines())\n",
    "    candidate_file = codecs.open(cand, 'r', 'utf-8')\n",
    "    candidate = candidate_file.readlines()\n",
    "    return candidate, references\n",
    "\n",
    "\n",
    "def count_ngram(candidate, references, n):\n",
    "    clipped_count = 0\n",
    "    count = 0\n",
    "    r = 0\n",
    "    c = 0\n",
    "    for si in range(len(candidate)):\n",
    "        # Calculate precision for each sentence\n",
    "        ref_counts = []\n",
    "        ref_lengths = []\n",
    "        # Build dictionary of ngram counts\n",
    "        for reference in references:\n",
    "            ref_sentence = reference[si]\n",
    "            ngram_d = {}\n",
    "            words = ref_sentence.strip().split()\n",
    "            ref_lengths.append(len(words))\n",
    "            limits = len(words) - n + 1\n",
    "            # loop through the sentance consider the ngram length\n",
    "            for i in range(limits):\n",
    "                ngram = ' '.join(words[i:i+n]).lower()\n",
    "                if ngram in ngram_d.keys():\n",
    "                    ngram_d[ngram] += 1\n",
    "                else:\n",
    "                    ngram_d[ngram] = 1\n",
    "            ref_counts.append(ngram_d)\n",
    "        # candidate\n",
    "        cand_sentence = candidate[si]\n",
    "        cand_dict = {}\n",
    "        words = cand_sentence.strip().split()\n",
    "        limits = len(words) - n + 1\n",
    "        for i in range(0, limits):\n",
    "            ngram = ' '.join(words[i:i + n]).lower()\n",
    "            if ngram in cand_dict:\n",
    "                cand_dict[ngram] += 1\n",
    "            else:\n",
    "                cand_dict[ngram] = 1\n",
    "        clipped_count += clip_count(cand_dict, ref_counts)\n",
    "        count += limits\n",
    "        r += best_length_match(ref_lengths, len(words))\n",
    "        c += len(words)\n",
    "    if clipped_count == 0:\n",
    "        pr = 0\n",
    "    else:\n",
    "        pr = float(clipped_count) / count\n",
    "    bp = brevity_penalty(c, r)\n",
    "    return pr, bp\n",
    "\n",
    "\n",
    "def clip_count(cand_d, ref_ds):\n",
    "    \"\"\"Count the clip count for each ngram considering all references\"\"\"\n",
    "    count = 0\n",
    "    for m in cand_d.keys():\n",
    "        m_w = cand_d[m]\n",
    "        m_max = 0\n",
    "        for ref in ref_ds:\n",
    "            if m in ref:\n",
    "                m_max = max(m_max, ref[m])\n",
    "        m_w = min(m_w, m_max)\n",
    "        count += m_w\n",
    "    return count\n",
    "\n",
    "\n",
    "def best_length_match(ref_l, cand_l):\n",
    "    \"\"\"Find the closest length of reference to that of candidate\"\"\"\n",
    "    least_diff = abs(cand_l-ref_l[0])\n",
    "    best = ref_l[0]\n",
    "    for ref in ref_l:\n",
    "        if abs(cand_l-ref) < least_diff:\n",
    "            least_diff = abs(cand_l-ref)\n",
    "            best = ref\n",
    "    return best\n",
    "\n",
    "\n",
    "def brevity_penalty(c, r):\n",
    "    if c > r:\n",
    "        bp = 1\n",
    "    else:\n",
    "        bp = math.exp(1-(float(r)/c))\n",
    "    return bp\n",
    "\n",
    "\n",
    "def geometric_mean(precisions):\n",
    "    return (reduce(operator.mul, precisions)) ** (1.0 / len(precisions))\n",
    "\n",
    "\n",
    "def BLEU(candidate, references):\n",
    "    precisions = []\n",
    "    for i in range(4):\n",
    "        pr, bp = count_ngram(candidate, references, i+1)\n",
    "        precisions.append(pr)\n",
    "    bleu = geometric_mean(precisions) * bp\n",
    "    return bleu\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    candidate, references = fetch_data(sys.argv[1], sys.argv[2])\n",
    "    bleu = BLEU(candidate, references)\n",
    "    print bleu\n",
    "    out = open('bleu_out.txt', 'w')\n",
    "    out.write(str(bleu))\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get each sentence\n",
    "def loadSentence(candidate, reference):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
